function import_sorted_units(ndiSession, probe)
% IMPORT_SORTED_UNITS - Import sorted spike units into NDI session
%
%   IMPORT_SORTED_UNITS(NDISESSION, PROBE)
%
%   Imports sorted spike units for the specified PROBE into the NDI session.
%   This function looks for spike sorting output files (spike times and cluster info)
%   generated by the vhNDISpikeSorter pipeline and creates NDI neuron elements.
%
%   NDISESSION is an ndi.session object.
%   PROBE is an ndi.probe object.

    arguments
        ndiSession {mustBeA(ndiSession, 'ndi.session')}
        probe {mustBeA(probe, 'ndi.probe')}
    end

    settingsDir = vhNDISpikeSorter.parameters.spikeSortingPath(ndiSession);

    pName = probe.elementstring();
    pName = char(pName); pName(isspace(pName)) = '_'; pName = replace(pName, '|', '_');

    % Filename pattern: sorted_st_PNAME_EPOCHID_CLUSTER.txt

    et = probe.epochtable();

    % Identify all clusters across all epochs
    clusterData = containers.Map('KeyType', 'double', 'ValueType', 'any');

    for j = 1:numel(et)
        epochID = et(j).epoch_id;

        prefix = ['sorted_st_' pName '_' epochID '_'];
        pat = fullfile(settingsDir, [prefix '*.txt']);
        files = dir(pat);

        for k = 1:length(files)
            fname = files(k).name;
            % Parse cluster ID: suffix .txt
            cStr = fname(length(prefix)+1 : end-4);
            cID = str2double(cStr);
            if isnan(cID), continue; end

            times = load(fullfile(settingsDir, fname), '-ascii');

            % Info file
            infoPrefix = ['sorted_ci_' pName '_' epochID '_'];
            infoFile = fullfile(settingsDir, [infoPrefix cStr '.mat']);
            quality = '';
            if exist(infoFile, 'file')
                tmp = load(infoFile);
                if isfield(tmp, 'clusterinfo') && isfield(tmp.clusterinfo, 'quality_label')
                    quality = tmp.clusterinfo.quality_label;
                end
            end

            if ~isKey(clusterData, cID)
                clusterData(cID) = struct('epochID', {}, 'times', {}, 'quality', {});
            end
            s = clusterData(cID);
            s(end+1).epochID = epochID;
            s(end).times = times;
            s(end).quality = quality;
            clusterData(cID) = s;
        end
    end

    % Create neurons
    keys = clusterData.keys;
    for k = 1:length(keys)
        cID = keys{k};
        dataStruct = clusterData(cID);

        neuron_name = [pName '_cluster' sprintf('%03d', cID)];

        % Check if element exists?
        % We can query session.
        % For now, attempt creation.

        element_neuron = ndi.neuron(ndiSession, neuron_name, probe.reference, 'spikes', probe, 0, [], []);

        % Document
        % Use quality from first epoch or consensus?
        qLabel = '';
        if ~isempty(dataStruct)
            qLabel = dataStruct(1).quality;
        end

        neuron_extracellular = struct();
        neuron_extracellular.cluster_index = cID;
        neuron_extracellular.quality_label = qLabel;

        % Read waveforms? Prompt: "Update the importing method so it reads the waveforms from these locations, too"
        % "from these locations" -> getSpikeWaveformFilename.
        % But that file has ALL spikes. We need spikes for THIS unit.
        % We have times. We can map times to indices?
        % Or we need to look up waveforms corresponding to `times`.
        % `extractwaveforms` saves times in `.vst`.
        % We can find indices of `times` in `.vst`.
        % Then read corresponding waveforms from `.vsw`.
        % AND compute mean waveform.

        all_waveforms = [];

        for m = 1:length(dataStruct)
            eID = dataStruct(m).epochID;
            ts = dataStruct(m).times;

            % Load all times for this epoch
            tFile = fullfile(settingsDir, vhNDISpikeSorter.parameters.getSpikeTimesFilename(probe, eID));
            wFile = fullfile(settingsDir, vhNDISpikeSorter.parameters.getSpikeWaveformFilename(probe, eID));

            if exist(tFile, 'file') && exist(wFile, 'file')
                fid = fopen(tFile, 'r', 'ieee-le');
                all_ts = fread(fid, 'float64');
                fclose(fid);

                % Find indices (approx match due to float?)
                % Using ismembertol?
                [L, locs] = ismembertol(ts, all_ts, 1e-6); % Tolerance?
                indices = locs(L);

                if ~isempty(indices)
                    % Read waveforms
                    % vhlspikewaveformfile allows reading specific indices?
                    % `readvhlspikewaveformfile` reads all usually.
                    % If file is large, reading all is slow.
                    % Assuming `readvhlspikewaveformfile` has standard read.
                    [w_epoch, h] = readvhlspikewaveformfile(wFile);
                    % w_epoch is S x C x N
                    w_unit = w_epoch(:, :, indices);

                    if isempty(all_waveforms)
                        all_waveforms = w_unit;
                    else
                        all_waveforms = cat(3, all_waveforms, w_unit);
                    end
                end
            end
        end

        mean_wave = [];
        if ~isempty(all_waveforms)
            mean_wave = mean(all_waveforms, 3);
        end

        neuron_extracellular.mean_waveform = mean_wave;

        neuron_doc = ndi.document('neuron_extracellular', ...
            'neuron_extracellular', neuron_extracellular, ...
            'base.session_id', ndiSession.id());
        neuron_doc = neuron_doc.set_dependency_value('element_id', element_neuron.id());
        ndiSession.database_add(neuron_doc);

        for m = 1:length(dataStruct)
            eID = dataStruct(m).epochID;
            ts = dataStruct(m).times;
            element_neuron.addepoch(eID, ndi.time.clocktype('dev_local_time'), ...
                [0 Inf], ts(:), ones(size(ts(:))));
        end
    end
end
